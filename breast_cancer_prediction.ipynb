{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading images and their labels\n",
    "X = np.load('X.npy') # images\n",
    "Y = np.load('Y.npy') # labels for the images (0 = no IDC, 1 = IDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[226 164 206]\n",
      "   [224 154 196]\n",
      "   [225 175 211]\n",
      "   ...\n",
      "   [240 221 237]\n",
      "   [232 184 214]\n",
      "   [243 213 235]]\n",
      "\n",
      "  [[217 142 188]\n",
      "   [221 130 179]\n",
      "   [224 150 196]\n",
      "   ...\n",
      "   [227 170 204]\n",
      "   [229 180 215]\n",
      "   [236 212 232]]\n",
      "\n",
      "  [[237 178 212]\n",
      "   [229 157 199]\n",
      "   [218 125 175]\n",
      "   ...\n",
      "   [221 184 217]\n",
      "   [190 153 193]\n",
      "   [227 164 208]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[217 145 192]\n",
      "   [214 129 184]\n",
      "   [212 129 183]\n",
      "   ...\n",
      "   [194 122 185]\n",
      "   [204 143 193]\n",
      "   [189 129 188]]\n",
      "\n",
      "  [[218 144 192]\n",
      "   [213 128 185]\n",
      "   [208 121 171]\n",
      "   ...\n",
      "   [136  79 145]\n",
      "   [184 111 174]\n",
      "   [188 112 176]]\n",
      "\n",
      "  [[212 125 181]\n",
      "   [211 136 181]\n",
      "   [220 162 206]\n",
      "   ...\n",
      "   [127  90 152]\n",
      "   [213 167 202]\n",
      "   [215 180 211]]]\n",
      "\n",
      "\n",
      " [[[219 150 197]\n",
      "   [217 158 201]\n",
      "   [228 173 205]\n",
      "   ...\n",
      "   [198 165 199]\n",
      "   [230 204 224]\n",
      "   [231 193 221]]\n",
      "\n",
      "  [[223 150 195]\n",
      "   [222 140 192]\n",
      "   [213 133 186]\n",
      "   ...\n",
      "   [218 143 193]\n",
      "   [218 148 197]\n",
      "   [215 131 185]]\n",
      "\n",
      "  [[203 125 176]\n",
      "   [218 143 192]\n",
      "   [227 163 199]\n",
      "   ...\n",
      "   [210 137 188]\n",
      "   [203 121 177]\n",
      "   [192 124 183]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[247 234 242]\n",
      "   [247 249 248]\n",
      "   [248 247 247]\n",
      "   ...\n",
      "   [245 240 242]\n",
      "   [249 244 247]\n",
      "   [243 234 239]]\n",
      "\n",
      "  [[249 243 246]\n",
      "   [243 240 247]\n",
      "   [248 241 246]\n",
      "   ...\n",
      "   [247 247 251]\n",
      "   [247 244 246]\n",
      "   [249 246 251]]\n",
      "\n",
      "  [[230 204 226]\n",
      "   [246 247 244]\n",
      "   [250 245 249]\n",
      "   ...\n",
      "   [249 243 250]\n",
      "   [251 248 248]\n",
      "   [248 247 247]]]\n",
      "\n",
      "\n",
      " [[[248 245 249]\n",
      "   [248 246 248]\n",
      "   [249 246 253]\n",
      "   ...\n",
      "   [249 249 248]\n",
      "   [247 246 249]\n",
      "   [248 244 248]]\n",
      "\n",
      "  [[248 246 246]\n",
      "   [248 245 247]\n",
      "   [250 248 248]\n",
      "   ...\n",
      "   [249 243 246]\n",
      "   [252 244 247]\n",
      "   [249 250 247]]\n",
      "\n",
      "  [[241 231 238]\n",
      "   [239 225 240]\n",
      "   [243 237 242]\n",
      "   ...\n",
      "   [248 244 251]\n",
      "   [245 248 249]\n",
      "   [249 242 251]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[248 247 249]\n",
      "   [248 247 249]\n",
      "   [248 247 249]\n",
      "   ...\n",
      "   [245 242 245]\n",
      "   [241 227 238]\n",
      "   [216 159 203]]\n",
      "\n",
      "  [[248 247 249]\n",
      "   [248 247 249]\n",
      "   [249 247 249]\n",
      "   ...\n",
      "   [249 242 249]\n",
      "   [229 193 222]\n",
      "   [161 111 171]]\n",
      "\n",
      "  [[249 247 249]\n",
      "   [249 247 249]\n",
      "   [249 247 249]\n",
      "   ...\n",
      "   [247 248 247]\n",
      "   [235 210 230]\n",
      "   [186 120 177]]]]\n"
     ]
    }
   ],
   "source": [
    "#making sure the data for X crossed over correctly\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#making sure the data for Y crosssed over correctly\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5547\n"
     ]
    }
   ],
   "source": [
    "#total number of images \n",
    "print('Total number of images: {}'.format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative IDC Images: 2759\n"
     ]
    }
   ],
   "source": [
    "#total number of negative IDC images\n",
    "print('Number of negative IDC Images: {}'.format(np.sum(Y==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive IDC Images: 2788\n"
     ]
    }
   ],
   "source": [
    "#total number of positive IDC images\n",
    "print('Number of positive IDC Images: {}'.format(np.sum(Y==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (Width, Height, Channels): (50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the images\n",
    "print('Image shape (Width, Height, Channels): {}'.format(X[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Sample Size\n",
    "x_train = x_train[0:30000] \n",
    "y_train = y_train[0:30000]\n",
    "x_test = x_test[0:30000] \n",
    "y_test = y_test[0:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale pizel intensity\n",
    "x_train = x_train / 256.0\n",
    "x_test = x_test / 256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (4437, 50, 50, 3)\n",
      "Testing Data Shape: (1110, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "#verifying shape\n",
    "print(\"Training Data Shape:\", x_train.shape)\n",
    "print(\"Testing Data Shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the first five images in the training set along with the labels\n",
    "for i in range(5):\n",
    "    plt.imshow(x_train[i], cmap='gray'), plt.axis(\"off\")\n",
    "    plt.title('IDC = %d'%y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.9453125  0.94140625 0.94921875]\n",
      "   [0.953125   0.92578125 0.94140625]\n",
      "   [0.953125   0.94140625 0.9375    ]\n",
      "   ...\n",
      "   [0.94921875 0.9375     0.9453125 ]\n",
      "   [0.9453125  0.94921875 0.953125  ]\n",
      "   [0.94921875 0.9296875  0.93359375]]\n",
      "\n",
      "  [[0.95703125 0.92578125 0.93359375]\n",
      "   [0.9375     0.94140625 0.93359375]\n",
      "   [0.95703125 0.92578125 0.94140625]\n",
      "   ...\n",
      "   [0.94921875 0.9375     0.9453125 ]\n",
      "   [0.9609375  0.93359375 0.9453125 ]\n",
      "   [0.9453125  0.953125   0.94140625]]\n",
      "\n",
      "  [[0.94921875 0.9375     0.9453125 ]\n",
      "   [0.953125   0.9296875  0.95703125]\n",
      "   [0.94921875 0.93359375 0.94140625]\n",
      "   ...\n",
      "   [0.94921875 0.94140625 0.9453125 ]\n",
      "   [0.94140625 0.9453125  0.94921875]\n",
      "   [0.953125   0.9296875  0.9453125 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7578125  0.328125   0.51171875]\n",
      "   [0.77734375 0.3828125  0.5625    ]\n",
      "   [0.83984375 0.43359375 0.60546875]\n",
      "   ...\n",
      "   [0.9453125  0.9296875  0.94140625]\n",
      "   [0.94140625 0.9296875  0.9375    ]\n",
      "   [0.93359375 0.78515625 0.84375   ]]\n",
      "\n",
      "  [[0.75       0.359375   0.52734375]\n",
      "   [0.80859375 0.3515625  0.54296875]\n",
      "   [0.83203125 0.40234375 0.578125  ]\n",
      "   ...\n",
      "   [0.9453125  0.8984375  0.921875  ]\n",
      "   [0.859375   0.5859375  0.7109375 ]\n",
      "   [0.80078125 0.3671875  0.52734375]]\n",
      "\n",
      "  [[0.78125    0.328125   0.53125   ]\n",
      "   [0.75       0.359375   0.546875  ]\n",
      "   [0.8359375  0.38671875 0.5546875 ]\n",
      "   ...\n",
      "   [0.7265625  0.37890625 0.546875  ]\n",
      "   [0.8203125  0.53515625 0.6328125 ]\n",
      "   [0.9140625  0.8125     0.86328125]]]\n",
      "\n",
      "\n",
      " [[[0.95703125 0.9609375  0.95703125]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   ...\n",
      "   [0.953125   0.9609375  0.95703125]\n",
      "   [0.95703125 0.95703125 0.95703125]\n",
      "   [0.95703125 0.9609375  0.95703125]]\n",
      "\n",
      "  [[0.95703125 0.9609375  0.95703125]\n",
      "   [0.95703125 0.9609375  0.95703125]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   ...\n",
      "   [0.95703125 0.96484375 0.95703125]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   [0.95703125 0.9609375  0.95703125]]\n",
      "\n",
      "  [[0.95703125 0.9609375  0.9609375 ]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   [0.95703125 0.9609375  0.9609375 ]\n",
      "   ...\n",
      "   [0.95703125 0.96484375 0.95703125]\n",
      "   [0.95703125 0.9609375  0.95703125]\n",
      "   [0.95703125 0.95703125 0.953125  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.94140625 0.9609375  0.953125  ]\n",
      "   [0.87890625 0.83984375 0.85546875]\n",
      "   [0.53515625 0.25       0.3828125 ]\n",
      "   ...\n",
      "   [0.96484375 0.95703125 0.95703125]\n",
      "   [0.9609375  0.94921875 0.94921875]\n",
      "   [0.953125   0.96484375 0.953125  ]]\n",
      "\n",
      "  [[0.9609375  0.9453125  0.95703125]\n",
      "   [0.95703125 0.95703125 0.95703125]\n",
      "   [0.84375    0.81640625 0.81640625]\n",
      "   ...\n",
      "   [0.953125   0.9609375  0.953125  ]\n",
      "   [0.95703125 0.96484375 0.95703125]\n",
      "   [0.95703125 0.953125   0.9453125 ]]\n",
      "\n",
      "  [[0.953125   0.95703125 0.953125  ]\n",
      "   [0.9453125  0.953125   0.953125  ]\n",
      "   [0.9609375  0.94921875 0.953125  ]\n",
      "   ...\n",
      "   [0.9609375  0.95703125 0.95703125]\n",
      "   [0.95703125 0.9453125  0.9609375 ]\n",
      "   [0.9609375  0.96875    0.953125  ]]]\n",
      "\n",
      "\n",
      " [[[0.890625   0.6875     0.78125   ]\n",
      "   [0.85546875 0.60546875 0.7421875 ]\n",
      "   [0.87890625 0.57421875 0.703125  ]\n",
      "   ...\n",
      "   [0.85546875 0.49609375 0.640625  ]\n",
      "   [0.84765625 0.51171875 0.66015625]\n",
      "   [0.85546875 0.57421875 0.6953125 ]]\n",
      "\n",
      "  [[0.84375    0.609375   0.71484375]\n",
      "   [0.83984375 0.5078125  0.65625   ]\n",
      "   [0.86328125 0.6171875  0.73046875]\n",
      "   ...\n",
      "   [0.8515625  0.5        0.640625  ]\n",
      "   [0.88671875 0.62109375 0.7421875 ]\n",
      "   [0.88671875 0.5859375  0.71484375]]\n",
      "\n",
      "  [[0.8984375  0.67578125 0.7734375 ]\n",
      "   [0.8515625  0.57421875 0.6875    ]\n",
      "   [0.8125     0.52734375 0.68359375]\n",
      "   ...\n",
      "   [0.88671875 0.6953125  0.79296875]\n",
      "   [0.84375    0.60546875 0.72265625]\n",
      "   [0.8515625  0.62109375 0.7265625 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8671875  0.62109375 0.7421875 ]\n",
      "   [0.8671875  0.62890625 0.75      ]\n",
      "   [0.8828125  0.66015625 0.76171875]\n",
      "   ...\n",
      "   [0.83203125 0.5234375  0.66796875]\n",
      "   [0.84765625 0.50390625 0.6640625 ]\n",
      "   [0.86328125 0.5546875  0.6796875 ]]\n",
      "\n",
      "  [[0.85546875 0.59375    0.71484375]\n",
      "   [0.87890625 0.62890625 0.74609375]\n",
      "   [0.875      0.64453125 0.74609375]\n",
      "   ...\n",
      "   [0.87890625 0.61328125 0.734375  ]\n",
      "   [0.87109375 0.625      0.74609375]\n",
      "   [0.875      0.60546875 0.7265625 ]]\n",
      "\n",
      "  [[0.86328125 0.625      0.75390625]\n",
      "   [0.85546875 0.58203125 0.7109375 ]\n",
      "   [0.83984375 0.52734375 0.68359375]\n",
      "   ...\n",
      "   [0.8515625  0.5390625  0.68359375]\n",
      "   [0.86328125 0.54296875 0.68359375]\n",
      "   [0.87890625 0.6484375  0.76171875]]]]\n"
     ]
    }
   ],
   "source": [
    "#printing the data to show that it's now 0-1\n",
    "print(x_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (4437, 7500)\n",
      "x_test shape:  (1110, 7500)\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "x_train_r = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3])\n",
    "x_test_r = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3])\n",
    "\n",
    "print(\"x_train shape: \",x_train_r.shape)\n",
    "print(\"x_test shape: \",x_test_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildclassifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_r.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 3s 6ms/step - loss: 0.6900 - accuracy: 0.5069\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6752 - accuracy: 0.5721\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6440 - accuracy: 0.6492\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6163 - accuracy: 0.6760\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5891 - accuracy: 0.7046\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5722 - accuracy: 0.7111\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5639 - accuracy: 0.7187\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5405 - accuracy: 0.7392\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.7411\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5320 - accuracy: 0.7368\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7471\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7620\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5239 - accuracy: 0.7585\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7422\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5097 - accuracy: 0.7620\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5238 - accuracy: 0.7514\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5079 - accuracy: 0.7658\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7557\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.7530\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5146 - accuracy: 0.7606\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5069 - accuracy: 0.7655\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.7603\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5033 - accuracy: 0.7625\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5017 - accuracy: 0.7722\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.7625\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4965 - accuracy: 0.7674\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5002 - accuracy: 0.7731\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5067 - accuracy: 0.7663\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.7706\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4919 - accuracy: 0.7741\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4976 - accuracy: 0.7709\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4981 - accuracy: 0.7698\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4927 - accuracy: 0.7744\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4847 - accuracy: 0.7825\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5070 - accuracy: 0.7649\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.7731\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4843 - accuracy: 0.7722\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4855 - accuracy: 0.7793\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.7660\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.5119 - accuracy: 0.7671\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.4986 - accuracy: 0.7701\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.7820\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.7733\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4855 - accuracy: 0.7841\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.7844\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4980 - accuracy: 0.7752\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4857 - accuracy: 0.7774\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4882 - accuracy: 0.7739\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4721 - accuracy: 0.7869\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4779 - accuracy: 0.7817\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4756 - accuracy: 0.7858\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4831 - accuracy: 0.7768\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4751 - accuracy: 0.7858\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4882 - accuracy: 0.7787\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4766 - accuracy: 0.7858\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4800 - accuracy: 0.7839\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7893\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.7777\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4675 - accuracy: 0.7906\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.7804\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.7866\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4679 - accuracy: 0.7890\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.7961\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.7847\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4677 - accuracy: 0.7931\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4618 - accuracy: 0.7961\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4551 - accuracy: 0.7923\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4868 - accuracy: 0.7839\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4656 - accuracy: 0.7969\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4623 - accuracy: 0.7928\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4637 - accuracy: 0.7906\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4639 - accuracy: 0.7890\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4602 - accuracy: 0.7928\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.7871\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8009\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.7890\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4505 - accuracy: 0.8012\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4488 - accuracy: 0.7985\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4536 - accuracy: 0.8055\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4593 - accuracy: 0.7944\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4453 - accuracy: 0.8039\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.7985\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7971\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4398 - accuracy: 0.8093\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4627 - accuracy: 0.7996\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4484 - accuracy: 0.8082\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4366 - accuracy: 0.8144\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4469 - accuracy: 0.8050\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7963\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4608 - accuracy: 0.7990\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4409 - accuracy: 0.8080\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4498 - accuracy: 0.8044\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.8115\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4291 - accuracy: 0.8131\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8142\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4369 - accuracy: 0.8077\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4650 - accuracy: 0.7963\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.8077\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4342 - accuracy: 0.8120\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4416 - accuracy: 0.8082\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4238 - accuracy: 0.8250\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4448 - accuracy: 0.8098\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4280 - accuracy: 0.8171\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.8112\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4526 - accuracy: 0.8012\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8020\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.8188\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4469 - accuracy: 0.8055\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4161 - accuracy: 0.8236\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.8245\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4392 - accuracy: 0.8109\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4461 - accuracy: 0.8031\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4309 - accuracy: 0.8166\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4136 - accuracy: 0.8255\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.8209\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4278 - accuracy: 0.8174\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.8174\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4103 - accuracy: 0.8296\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4104 - accuracy: 0.8277\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4048 - accuracy: 0.8282\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4069 - accuracy: 0.8307\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4554 - accuracy: 0.8023\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4098 - accuracy: 0.8312\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8217\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4163 - accuracy: 0.8223\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3950 - accuracy: 0.8355\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.4152 - accuracy: 0.8315\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8320\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4082 - accuracy: 0.8247\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.8253\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.8128\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4309 - accuracy: 0.8082\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4093 - accuracy: 0.8236\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4001 - accuracy: 0.8358\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4030 - accuracy: 0.8307\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3982 - accuracy: 0.8339\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.8418\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4065 - accuracy: 0.8272\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4120 - accuracy: 0.8301\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4096 - accuracy: 0.8236\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3871 - accuracy: 0.8391\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4071 - accuracy: 0.8304\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3910 - accuracy: 0.8391\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4027 - accuracy: 0.8258\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3903 - accuracy: 0.8342\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3986 - accuracy: 0.8347\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4084 - accuracy: 0.8253\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3884 - accuracy: 0.8412\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3836 - accuracy: 0.8410\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3905 - accuracy: 0.8355\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4150 - accuracy: 0.8193\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3914 - accuracy: 0.8412\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3842 - accuracy: 0.8428\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3753 - accuracy: 0.8431\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3812 - accuracy: 0.8410\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8190\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3792 - accuracy: 0.8453\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3862 - accuracy: 0.8418\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.8364\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.8537\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8529\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3776 - accuracy: 0.8461\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3630 - accuracy: 0.8556\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4193 - accuracy: 0.8223\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8493\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3907 - accuracy: 0.8407\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3709 - accuracy: 0.8493\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.8447\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3658 - accuracy: 0.8556\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3675 - accuracy: 0.8520\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8461\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3648 - accuracy: 0.8558\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3630 - accuracy: 0.8583\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3573 - accuracy: 0.8612\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3768 - accuracy: 0.8483\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3582 - accuracy: 0.8556\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3526 - accuracy: 0.8591\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3689 - accuracy: 0.8529\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3747 - accuracy: 0.8464\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.8610\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.8220\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3808 - accuracy: 0.8374\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3507 - accuracy: 0.8639\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3502 - accuracy: 0.8677\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3840 - accuracy: 0.8336\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3492 - accuracy: 0.8604\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3436 - accuracy: 0.8653\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3506 - accuracy: 0.8607\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3620 - accuracy: 0.8520\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4003 - accuracy: 0.8307\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3480 - accuracy: 0.8631\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3440 - accuracy: 0.8653\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3483 - accuracy: 0.8599\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3409 - accuracy: 0.8650\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3655 - accuracy: 0.8518\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3706 - accuracy: 0.8464\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3407 - accuracy: 0.8685\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3589 - accuracy: 0.8547\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3620 - accuracy: 0.8520\n",
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 3s 6ms/step - loss: 0.6905 - accuracy: 0.5009\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6835 - accuracy: 0.5510\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6590 - accuracy: 0.6083\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6353 - accuracy: 0.6646\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6184 - accuracy: 0.6800\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6094 - accuracy: 0.6946\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5880 - accuracy: 0.7100\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5855 - accuracy: 0.7114\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5721 - accuracy: 0.7092\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5662 - accuracy: 0.7255\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5571 - accuracy: 0.7230\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5485 - accuracy: 0.7382\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5309 - accuracy: 0.7533\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5270 - accuracy: 0.7520\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5435 - accuracy: 0.7282\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7568\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5315 - accuracy: 0.7428\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5167 - accuracy: 0.7609\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.7693\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5024 - accuracy: 0.7712\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5088 - accuracy: 0.7644\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5095 - accuracy: 0.7655\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5042 - accuracy: 0.7633\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5142 - accuracy: 0.7631\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5069 - accuracy: 0.7671\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.7641\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4946 - accuracy: 0.7739\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5088 - accuracy: 0.7568\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4988 - accuracy: 0.7720\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4905 - accuracy: 0.7787\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4990 - accuracy: 0.7685\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4915 - accuracy: 0.7709\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5095 - accuracy: 0.7636\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4963 - accuracy: 0.7706\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4961 - accuracy: 0.7717\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5019 - accuracy: 0.7663\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4921 - accuracy: 0.7709\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4861 - accuracy: 0.7774\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4910 - accuracy: 0.7801\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4904 - accuracy: 0.7744\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4967 - accuracy: 0.7741\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4865 - accuracy: 0.7793\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4949 - accuracy: 0.7733\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4833 - accuracy: 0.7852\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4816 - accuracy: 0.7787\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4871 - accuracy: 0.7836\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4893 - accuracy: 0.7785\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4794 - accuracy: 0.7785\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4914 - accuracy: 0.7750\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4822 - accuracy: 0.7833\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4825 - accuracy: 0.7809\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5027 - accuracy: 0.7655\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4746 - accuracy: 0.7860\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.7806\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4755 - accuracy: 0.7833\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4753 - accuracy: 0.7871\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4757 - accuracy: 0.7885\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.7871\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4770 - accuracy: 0.7844\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4728 - accuracy: 0.7833\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7931\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4852 - accuracy: 0.7768\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4850 - accuracy: 0.7844\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4906 - accuracy: 0.7741\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4691 - accuracy: 0.7855\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5039 - accuracy: 0.7733\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4636 - accuracy: 0.7947\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4843 - accuracy: 0.7741\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4676 - accuracy: 0.7947\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4608 - accuracy: 0.7906\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4567 - accuracy: 0.7966\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4729 - accuracy: 0.7898\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.7917\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4631 - accuracy: 0.7961\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4691 - accuracy: 0.7893\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4646 - accuracy: 0.7939\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4618 - accuracy: 0.7998\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4627 - accuracy: 0.7966\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4621 - accuracy: 0.7966\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4502 - accuracy: 0.8004\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4796 - accuracy: 0.7860\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4615 - accuracy: 0.7969\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4473 - accuracy: 0.8020\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7869\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4587 - accuracy: 0.7998\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.8015\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8034\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.7988\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4482 - accuracy: 0.8131\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.7985\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4448 - accuracy: 0.8069\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.8055\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.8082\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8052\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4536 - accuracy: 0.8004\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4547 - accuracy: 0.8034\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4566 - accuracy: 0.7993\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4555 - accuracy: 0.7969\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4501 - accuracy: 0.8034\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.8055\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4434 - accuracy: 0.8055\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.8147\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4311 - accuracy: 0.8131\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.8123\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4489 - accuracy: 0.8066\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.8123\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.8015\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4448 - accuracy: 0.8107\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4334 - accuracy: 0.8166\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8098\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4309 - accuracy: 0.8182\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4604 - accuracy: 0.7958\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4218 - accuracy: 0.8190\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.8098\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4239 - accuracy: 0.8217\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.8207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4235 - accuracy: 0.8193\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8236\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4127 - accuracy: 0.8231\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4444 - accuracy: 0.8006\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4348 - accuracy: 0.8220\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4393 - accuracy: 0.8080\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.8236\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4183 - accuracy: 0.8315\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4143 - accuracy: 0.8258\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.8163\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4215 - accuracy: 0.8204\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.8272\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4069 - accuracy: 0.8277\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4315 - accuracy: 0.8158\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4138 - accuracy: 0.8309\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4078 - accuracy: 0.8304\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4094 - accuracy: 0.8288\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4043 - accuracy: 0.8301\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4134 - accuracy: 0.8266\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4212 - accuracy: 0.8209\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4265 - accuracy: 0.8226\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4040 - accuracy: 0.8350\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3966 - accuracy: 0.8366\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4140 - accuracy: 0.8247\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4257 - accuracy: 0.8207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4073 - accuracy: 0.8334\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3919 - accuracy: 0.8399\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3948 - accuracy: 0.8369\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3982 - accuracy: 0.8345\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4324 - accuracy: 0.8161\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8345\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4319 - accuracy: 0.8139\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4034 - accuracy: 0.8334\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3940 - accuracy: 0.8396\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3822 - accuracy: 0.8382\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4272 - accuracy: 0.8174\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4138 - accuracy: 0.8217\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8391\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3911 - accuracy: 0.8420\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.4000 - accuracy: 0.8353\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.3944 - accuracy: 0.8420\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3799 - accuracy: 0.8469\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8431\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4153 - accuracy: 0.8301\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3977 - accuracy: 0.8355\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3963 - accuracy: 0.8350\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3810 - accuracy: 0.8453\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3765 - accuracy: 0.8431\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3786 - accuracy: 0.8431\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3856 - accuracy: 0.8420\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3928 - accuracy: 0.8355\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.8423\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3941 - accuracy: 0.8304\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3849 - accuracy: 0.8420\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3616 - accuracy: 0.8602\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3608 - accuracy: 0.8572\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3821 - accuracy: 0.8418\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3668 - accuracy: 0.8537\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3685 - accuracy: 0.8515\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3659 - accuracy: 0.8531\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3700 - accuracy: 0.8561\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3637 - accuracy: 0.8550\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3694 - accuracy: 0.8485\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4260 - accuracy: 0.8247\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3668 - accuracy: 0.8520\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3824 - accuracy: 0.8404\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3661 - accuracy: 0.8545\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8464\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3638 - accuracy: 0.8539\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3433 - accuracy: 0.8639\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3452 - accuracy: 0.8656\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4092 - accuracy: 0.8245\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3967 - accuracy: 0.8374\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3704 - accuracy: 0.8531\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3558 - accuracy: 0.8623\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3667 - accuracy: 0.8507\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3641 - accuracy: 0.8518\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3644 - accuracy: 0.8510\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3547 - accuracy: 0.8599\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3552 - accuracy: 0.8561\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3410 - accuracy: 0.8669\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3456 - accuracy: 0.8610\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8664\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3938 - accuracy: 0.8353\n",
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 3s 6ms/step - loss: 0.6920 - accuracy: 0.5031\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6879 - accuracy: 0.5356\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6735 - accuracy: 0.5661\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6474 - accuracy: 0.6424\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6257 - accuracy: 0.6811\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6095 - accuracy: 0.6922\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5955 - accuracy: 0.7081\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5828 - accuracy: 0.7084\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5779 - accuracy: 0.7149\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5656 - accuracy: 0.7149\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.7401\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.7417\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5273 - accuracy: 0.7579\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5313 - accuracy: 0.7476\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.7536\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5305 - accuracy: 0.7436\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5197 - accuracy: 0.7614\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5168 - accuracy: 0.7614\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5172 - accuracy: 0.7612\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5092 - accuracy: 0.7622\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5079 - accuracy: 0.7641\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5076 - accuracy: 0.7652\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.7679\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5020 - accuracy: 0.7733\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5030 - accuracy: 0.7693\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.7576\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5128 - accuracy: 0.7603\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4987 - accuracy: 0.7701\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4982 - accuracy: 0.7682\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5128 - accuracy: 0.7636\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5017 - accuracy: 0.7685\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4918 - accuracy: 0.7766\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4986 - accuracy: 0.7750\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.7736\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4880 - accuracy: 0.7787\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4895 - accuracy: 0.7744\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.7725\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4853 - accuracy: 0.7785\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4934 - accuracy: 0.7706\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7779\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4888 - accuracy: 0.7720\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4839 - accuracy: 0.7831\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4904 - accuracy: 0.7787\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4817 - accuracy: 0.7828\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4863 - accuracy: 0.7847\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4904 - accuracy: 0.7771\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.7652\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4843 - accuracy: 0.7787\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4831 - accuracy: 0.7798\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.7874\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.7863\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4880 - accuracy: 0.7771\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4796 - accuracy: 0.7828\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4886 - accuracy: 0.7774\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4774 - accuracy: 0.7841\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4823 - accuracy: 0.7841\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4793 - accuracy: 0.7860\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4820 - accuracy: 0.7831\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.7928\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4668 - accuracy: 0.7915\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4820 - accuracy: 0.7882\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4770 - accuracy: 0.7871\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.7896\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.7831\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4847 - accuracy: 0.7785\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.7866\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7939\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4648 - accuracy: 0.7944\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.7874\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4757 - accuracy: 0.7887\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4781 - accuracy: 0.7898\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7866\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4676 - accuracy: 0.7955\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7877\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7969\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7928\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4622 - accuracy: 0.7963\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4709 - accuracy: 0.7931\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.8042\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4837 - accuracy: 0.7866\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4719 - accuracy: 0.7850\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4623 - accuracy: 0.8031\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4535 - accuracy: 0.8044\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.8006\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4512 - accuracy: 0.8058\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4562 - accuracy: 0.7990\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4636 - accuracy: 0.8004\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4490 - accuracy: 0.8082\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4574 - accuracy: 0.8006\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4658 - accuracy: 0.7969\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4535 - accuracy: 0.8077\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4513 - accuracy: 0.8009\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4534 - accuracy: 0.8025\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.8063\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4429 - accuracy: 0.8088\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.8082\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.7996\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4656 - accuracy: 0.7925\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4424 - accuracy: 0.8071\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4458 - accuracy: 0.8025\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4516 - accuracy: 0.8034\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4456 - accuracy: 0.8058\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4601 - accuracy: 0.7979\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8144\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.8034\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4349 - accuracy: 0.8136\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.8142\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4428 - accuracy: 0.8163\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4368 - accuracy: 0.8109\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4539 - accuracy: 0.8025\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.8098\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.8209\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4363 - accuracy: 0.8117\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4338 - accuracy: 0.8169\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4353 - accuracy: 0.8169\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4297 - accuracy: 0.8228\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4414 - accuracy: 0.8082\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.8188\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.8207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8196\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8234\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4289 - accuracy: 0.8171\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4376 - accuracy: 0.8096\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4170 - accuracy: 0.8239\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4199 - accuracy: 0.8263\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8193\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4277 - accuracy: 0.8209\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4195 - accuracy: 0.8258\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4256 - accuracy: 0.8171\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.8182\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4241 - accuracy: 0.8242\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4449 - accuracy: 0.8090\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4258 - accuracy: 0.8196\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4131 - accuracy: 0.8261\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4121 - accuracy: 0.8288\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4111 - accuracy: 0.8277\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4295 - accuracy: 0.8196\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8261\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8274\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4190 - accuracy: 0.8247\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4174 - accuracy: 0.8293\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4188 - accuracy: 0.8231\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4056 - accuracy: 0.8342\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4143 - accuracy: 0.8280\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3984 - accuracy: 0.8345\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4145 - accuracy: 0.8274\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8361\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3991 - accuracy: 0.8320\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3974 - accuracy: 0.8361\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4228 - accuracy: 0.8274\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4233 - accuracy: 0.8261\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4057 - accuracy: 0.8301\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3943 - accuracy: 0.8380\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3876 - accuracy: 0.8410\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3963 - accuracy: 0.8423\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4196 - accuracy: 0.8277\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4114 - accuracy: 0.8274\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3952 - accuracy: 0.8404\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3955 - accuracy: 0.8372\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8209\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3955 - accuracy: 0.8350\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3886 - accuracy: 0.8442\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3842 - accuracy: 0.8496\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3922 - accuracy: 0.8401\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3908 - accuracy: 0.8377\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3979 - accuracy: 0.8372\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3784 - accuracy: 0.8480\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3828 - accuracy: 0.8439\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3962 - accuracy: 0.8404\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3848 - accuracy: 0.8477\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4143 - accuracy: 0.8282\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3706 - accuracy: 0.8561\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3732 - accuracy: 0.8539\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3823 - accuracy: 0.8447\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3990 - accuracy: 0.8372\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3950 - accuracy: 0.8399\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3789 - accuracy: 0.8518\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3763 - accuracy: 0.8504\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3681 - accuracy: 0.8593\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3736 - accuracy: 0.8537\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8493\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3776 - accuracy: 0.8499\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4132 - accuracy: 0.8288\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3799 - accuracy: 0.8447\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.8537\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3606 - accuracy: 0.8607\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3958 - accuracy: 0.8388\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3694 - accuracy: 0.8529\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3613 - accuracy: 0.8575\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3725 - accuracy: 0.8545\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3935 - accuracy: 0.8396\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3657 - accuracy: 0.8572\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3674 - accuracy: 0.8564\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3673 - accuracy: 0.8564\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3881 - accuracy: 0.8401\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3661 - accuracy: 0.8599\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3754 - accuracy: 0.8515\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3707 - accuracy: 0.8512\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3707 - accuracy: 0.8523\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8456\n",
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 3s 7ms/step - loss: 0.6907 - accuracy: 0.5011\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6828 - accuracy: 0.5333\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6513 - accuracy: 0.6228\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6160 - accuracy: 0.6620\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5939 - accuracy: 0.6925\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5853 - accuracy: 0.7012\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5658 - accuracy: 0.7169\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5585 - accuracy: 0.7180\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5685 - accuracy: 0.7120\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.7420\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5467 - accuracy: 0.7380\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.7461\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7482\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.7496\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5363 - accuracy: 0.7415\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.7607\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5142 - accuracy: 0.7599\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7626\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5148 - accuracy: 0.7539\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7474\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5142 - accuracy: 0.7572\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5055 - accuracy: 0.7620\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5059 - accuracy: 0.7672\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5002 - accuracy: 0.7688\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5027 - accuracy: 0.7650\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5150 - accuracy: 0.7572\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.7631\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5171 - accuracy: 0.7553\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.7628\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5060 - accuracy: 0.7626\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4990 - accuracy: 0.7704\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4926 - accuracy: 0.7683\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4979 - accuracy: 0.7699\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5039 - accuracy: 0.7631\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4933 - accuracy: 0.7734\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5031 - accuracy: 0.7650\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4864 - accuracy: 0.7764\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.7669\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.7683\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4892 - accuracy: 0.7750\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4977 - accuracy: 0.7707\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4811 - accuracy: 0.7791\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.7758\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4912 - accuracy: 0.7737\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.7731\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.7788\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4869 - accuracy: 0.7769\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4832 - accuracy: 0.7747\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.7553\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4898 - accuracy: 0.7691\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4816 - accuracy: 0.7766\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4932 - accuracy: 0.7729\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.7799\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4798 - accuracy: 0.7810\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.7853\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4713 - accuracy: 0.7877\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4735 - accuracy: 0.7847\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4748 - accuracy: 0.7820\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4681 - accuracy: 0.7847\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4687 - accuracy: 0.7920\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4735 - accuracy: 0.7850\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.7726\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4747 - accuracy: 0.7837\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4732 - accuracy: 0.7866\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.7899\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7764\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4742 - accuracy: 0.7847\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4658 - accuracy: 0.7885\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4633 - accuracy: 0.7964\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4586 - accuracy: 0.7934\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4646 - accuracy: 0.7896\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4637 - accuracy: 0.7926\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.7966\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.7888\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4575 - accuracy: 0.7961\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4617 - accuracy: 0.7904\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.7793\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4558 - accuracy: 0.7910\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4589 - accuracy: 0.7948\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4600 - accuracy: 0.7915\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4549 - accuracy: 0.7937\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4579 - accuracy: 0.7926\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4909 - accuracy: 0.7650\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4715 - accuracy: 0.7847\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4615 - accuracy: 0.7902\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.8012\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4495 - accuracy: 0.7988\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4539 - accuracy: 0.7934\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4506 - accuracy: 0.8053\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4464 - accuracy: 0.7991\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.8075\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7942\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4511 - accuracy: 0.8007\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4355 - accuracy: 0.8048\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4420 - accuracy: 0.8056\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4424 - accuracy: 0.8023\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.7934\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4359 - accuracy: 0.8061\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4362 - accuracy: 0.8045\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4578 - accuracy: 0.7896\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4566 - accuracy: 0.7920\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4503 - accuracy: 0.7996\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4356 - accuracy: 0.8102\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4593 - accuracy: 0.7980\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4328 - accuracy: 0.8121\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4412 - accuracy: 0.8007\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4476 - accuracy: 0.7977\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4444 - accuracy: 0.8034\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4583 - accuracy: 0.7866\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4297 - accuracy: 0.8167\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8102\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.8153\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4302 - accuracy: 0.8080\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4359 - accuracy: 0.8085\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4363 - accuracy: 0.8058\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4298 - accuracy: 0.8121\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4366 - accuracy: 0.8102\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4342 - accuracy: 0.8099\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4313 - accuracy: 0.8107\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4278 - accuracy: 0.8126\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.8167\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8053\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4135 - accuracy: 0.8218\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4257 - accuracy: 0.8186\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.8123\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8210\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4594 - accuracy: 0.7918\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4227 - accuracy: 0.8153\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4090 - accuracy: 0.8191\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4155 - accuracy: 0.8180\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8088\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4116 - accuracy: 0.8231\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4163 - accuracy: 0.8202\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.8064\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4193 - accuracy: 0.8213\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.8172\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4050 - accuracy: 0.8259\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4206 - accuracy: 0.8137\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.8267\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4142 - accuracy: 0.8207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8250\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4094 - accuracy: 0.8245\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8242\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8313\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4062 - accuracy: 0.8253\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4166 - accuracy: 0.8210\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3972 - accuracy: 0.8296\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3963 - accuracy: 0.8302\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4045 - accuracy: 0.8240\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4133 - accuracy: 0.8202\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4008 - accuracy: 0.8267\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3958 - accuracy: 0.8334\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.8069\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8231\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3942 - accuracy: 0.8340\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3969 - accuracy: 0.8302\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3979 - accuracy: 0.8267\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3913 - accuracy: 0.8318\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3810 - accuracy: 0.8421\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3916 - accuracy: 0.8340\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4029 - accuracy: 0.8307\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3833 - accuracy: 0.8396\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3950 - accuracy: 0.8296\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3858 - accuracy: 0.8383\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3749 - accuracy: 0.8434\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4023 - accuracy: 0.8288\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3826 - accuracy: 0.8372\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3897 - accuracy: 0.8350\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4059 - accuracy: 0.8272\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3874 - accuracy: 0.8304\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8394\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3704 - accuracy: 0.8453\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3724 - accuracy: 0.8415\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3783 - accuracy: 0.8356\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3843 - accuracy: 0.8323\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3795 - accuracy: 0.8391\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8429\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3600 - accuracy: 0.8496\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3805 - accuracy: 0.8361\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3637 - accuracy: 0.8478\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3834 - accuracy: 0.8302\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8231\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3588 - accuracy: 0.8502\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3880 - accuracy: 0.8302\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3535 - accuracy: 0.8567\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3655 - accuracy: 0.8478\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3732 - accuracy: 0.8429\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3865 - accuracy: 0.8369\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3725 - accuracy: 0.8405\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8534\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3731 - accuracy: 0.8496\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3712 - accuracy: 0.8469\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3579 - accuracy: 0.8537\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.8496\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3620 - accuracy: 0.8483\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.8486\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3429 - accuracy: 0.8594\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3557 - accuracy: 0.8475\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3585 - accuracy: 0.8478\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3597 - accuracy: 0.8453\n",
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 3s 7ms/step - loss: 0.6897 - accuracy: 0.5035\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6817 - accuracy: 0.5452\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6572 - accuracy: 0.6244\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6272 - accuracy: 0.6668\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.6124 - accuracy: 0.6796\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5948 - accuracy: 0.6942\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5830 - accuracy: 0.7071\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5709 - accuracy: 0.7090\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5748 - accuracy: 0.7158\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5636 - accuracy: 0.7258\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5566 - accuracy: 0.7271\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5365 - accuracy: 0.7447\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.5402 - accuracy: 0.7447\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.7334\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5263 - accuracy: 0.7461\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5188 - accuracy: 0.7615\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5368 - accuracy: 0.7355\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7488\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5221 - accuracy: 0.7501\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5131 - accuracy: 0.7623\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.7534\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.5117 - accuracy: 0.7561\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.7528\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.7580\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5057 - accuracy: 0.7596\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.7607\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.7623\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4996 - accuracy: 0.7696\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5204 - accuracy: 0.7531\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.7618\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5075 - accuracy: 0.7677\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5017 - accuracy: 0.7723\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4966 - accuracy: 0.7707\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4944 - accuracy: 0.7739\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4993 - accuracy: 0.7720\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4934 - accuracy: 0.7742\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5065 - accuracy: 0.7672\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4976 - accuracy: 0.7704\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4950 - accuracy: 0.7693\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.7731\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5002 - accuracy: 0.7666\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4874 - accuracy: 0.7747\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5041 - accuracy: 0.7666\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4997 - accuracy: 0.7655\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4947 - accuracy: 0.7753\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4863 - accuracy: 0.7772\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4903 - accuracy: 0.7780\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4868 - accuracy: 0.7756\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.7799\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4971 - accuracy: 0.7683\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4840 - accuracy: 0.7791\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4808 - accuracy: 0.7804\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4876 - accuracy: 0.7810\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4839 - accuracy: 0.7793\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4881 - accuracy: 0.7766\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4841 - accuracy: 0.7810\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.7737\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5019 - accuracy: 0.7720\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.7756\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4733 - accuracy: 0.7845\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4872 - accuracy: 0.7783\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4721 - accuracy: 0.7885\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4856 - accuracy: 0.7729\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4896 - accuracy: 0.7723\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4812 - accuracy: 0.7742\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4803 - accuracy: 0.7769\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.7758\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7904\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4765 - accuracy: 0.7829\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4773 - accuracy: 0.7875\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4742 - accuracy: 0.7929\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4726 - accuracy: 0.7850\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4726 - accuracy: 0.7912\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.7915\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.7793\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4645 - accuracy: 0.7929\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4702 - accuracy: 0.7907\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7939\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4714 - accuracy: 0.7918\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.7880\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4693 - accuracy: 0.7907\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4784 - accuracy: 0.7842\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4616 - accuracy: 0.7942\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.7942\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4688 - accuracy: 0.7885\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4546 - accuracy: 0.7964\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7988\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.7934\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4677 - accuracy: 0.7896\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4734 - accuracy: 0.7845\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4715 - accuracy: 0.7907\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4537 - accuracy: 0.7964\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4799 - accuracy: 0.7845\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4538 - accuracy: 0.8015\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4571 - accuracy: 0.7980\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4617 - accuracy: 0.7910\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.7891\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4885 - accuracy: 0.7799\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4587 - accuracy: 0.7958\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4594 - accuracy: 0.7920\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4609 - accuracy: 0.7942\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4516 - accuracy: 0.8037\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4525 - accuracy: 0.8007\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4486 - accuracy: 0.8099\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4464 - accuracy: 0.8061\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4657 - accuracy: 0.7985\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4435 - accuracy: 0.8050\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4505 - accuracy: 0.8045\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7988\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4485 - accuracy: 0.8039\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4524 - accuracy: 0.7996\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.8056\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4551 - accuracy: 0.8058\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.8053\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.8058\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4476 - accuracy: 0.8056\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4344 - accuracy: 0.8121\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4547 - accuracy: 0.7988\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4419 - accuracy: 0.8050\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4351 - accuracy: 0.8129\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4273 - accuracy: 0.8129\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4407 - accuracy: 0.8080\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4311 - accuracy: 0.8126\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4377 - accuracy: 0.8112\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8121\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4463 - accuracy: 0.8053\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4358 - accuracy: 0.8153\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4271 - accuracy: 0.8177\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4436 - accuracy: 0.8015\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4252 - accuracy: 0.8177\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4428 - accuracy: 0.8088\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4449 - accuracy: 0.8088\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4229 - accuracy: 0.8213\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4156 - accuracy: 0.8275\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4151 - accuracy: 0.8218\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4258 - accuracy: 0.8164\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4321 - accuracy: 0.8142\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.8188\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4100 - accuracy: 0.8299\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4225 - accuracy: 0.8259\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.8180\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8223\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4223 - accuracy: 0.8221\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4103 - accuracy: 0.8275\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4144 - accuracy: 0.8288\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8272\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4060 - accuracy: 0.8315\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4089 - accuracy: 0.8323\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4329 - accuracy: 0.8129\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4115 - accuracy: 0.8291\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4120 - accuracy: 0.8237\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4116 - accuracy: 0.8280\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4107 - accuracy: 0.8272\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3927 - accuracy: 0.8442\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4263 - accuracy: 0.8210\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3962 - accuracy: 0.8364\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4114 - accuracy: 0.8267\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4036 - accuracy: 0.8348\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4101 - accuracy: 0.8267\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3875 - accuracy: 0.8445\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8264\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8340\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4109 - accuracy: 0.8218\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4036 - accuracy: 0.8361\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3991 - accuracy: 0.8364\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8307\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3974 - accuracy: 0.8369\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.8451\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3828 - accuracy: 0.8464\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4060 - accuracy: 0.8280\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4007 - accuracy: 0.8359\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3956 - accuracy: 0.8388\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3792 - accuracy: 0.8472\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4145 - accuracy: 0.8248\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4004 - accuracy: 0.8310\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3944 - accuracy: 0.8359\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3808 - accuracy: 0.8472\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3961 - accuracy: 0.8334\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3973 - accuracy: 0.8342\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3691 - accuracy: 0.8532\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3709 - accuracy: 0.8553\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3659 - accuracy: 0.8556\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3907 - accuracy: 0.8378\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4331 - accuracy: 0.8191\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3807 - accuracy: 0.8461\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8483\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3653 - accuracy: 0.8575\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3793 - accuracy: 0.8464\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8524\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3857 - accuracy: 0.8421\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3748 - accuracy: 0.8483\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3783 - accuracy: 0.8459\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3596 - accuracy: 0.8567\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3600 - accuracy: 0.8597\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3724 - accuracy: 0.8529\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3618 - accuracy: 0.8578\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3677 - accuracy: 0.8521\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3600 - accuracy: 0.8553\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.8475\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3545 - accuracy: 0.8605\n",
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 2s 7ms/step - loss: 0.6904 - accuracy: 0.5016\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6847 - accuracy: 0.5284\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6602 - accuracy: 0.6217\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6116 - accuracy: 0.6847\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5940 - accuracy: 0.6969\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.7017\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5654 - accuracy: 0.7198\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5598 - accuracy: 0.7209\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5493 - accuracy: 0.7363\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5439 - accuracy: 0.7485\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.7485\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.7469\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5218 - accuracy: 0.7537\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5137 - accuracy: 0.7591\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5236 - accuracy: 0.7491\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5227 - accuracy: 0.7493\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5052 - accuracy: 0.7691\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.7647\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5178 - accuracy: 0.7572\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5187 - accuracy: 0.7555\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5014 - accuracy: 0.7699\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5076 - accuracy: 0.7610\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.7593\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5076 - accuracy: 0.7620\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5102 - accuracy: 0.7680\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5057 - accuracy: 0.7666\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4969 - accuracy: 0.7669\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.7718\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4979 - accuracy: 0.7672\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.7710\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4967 - accuracy: 0.7701\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4999 - accuracy: 0.7672\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.7718\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4888 - accuracy: 0.7758\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.7691\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4925 - accuracy: 0.7737\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4978 - accuracy: 0.7729\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.7758\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4889 - accuracy: 0.7726\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4904 - accuracy: 0.7791\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5035 - accuracy: 0.7691\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4906 - accuracy: 0.7764\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4804 - accuracy: 0.7823\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4888 - accuracy: 0.7761\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.7639\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4927 - accuracy: 0.7734\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4962 - accuracy: 0.7720\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4924 - accuracy: 0.7739\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4833 - accuracy: 0.7804\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4783 - accuracy: 0.7785\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5052 - accuracy: 0.7699\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4772 - accuracy: 0.7858\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.7810\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4784 - accuracy: 0.7788\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.7837\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4891 - accuracy: 0.7731\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4763 - accuracy: 0.7837\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4660 - accuracy: 0.7896\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4694 - accuracy: 0.7899\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4818 - accuracy: 0.7820\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4906 - accuracy: 0.7731\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4723 - accuracy: 0.7907\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4913 - accuracy: 0.7758\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4694 - accuracy: 0.7877\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4728 - accuracy: 0.7861\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4695 - accuracy: 0.7875\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4754 - accuracy: 0.7820\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.7872\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4722 - accuracy: 0.7872\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.7912\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4668 - accuracy: 0.7869\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4719 - accuracy: 0.7883\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4628 - accuracy: 0.7972\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.7934\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4618 - accuracy: 0.7958\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.7907\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4556 - accuracy: 0.7985\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.7988\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4548 - accuracy: 0.8021\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4686 - accuracy: 0.7872\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4724 - accuracy: 0.7864\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.7953\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4600 - accuracy: 0.7953\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4808 - accuracy: 0.7880\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4583 - accuracy: 0.7966\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4479 - accuracy: 0.8029\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4578 - accuracy: 0.7996\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4577 - accuracy: 0.8002\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.8067\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4578 - accuracy: 0.7961\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4574 - accuracy: 0.8021\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4572 - accuracy: 0.7975\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4468 - accuracy: 0.8083\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.8102\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.7780\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4538 - accuracy: 0.8021\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4436 - accuracy: 0.8039\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4522 - accuracy: 0.7991\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4463 - accuracy: 0.8050\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.8080\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4419 - accuracy: 0.8064\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4411 - accuracy: 0.8067\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.8034\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4366 - accuracy: 0.8102\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.7826\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4583 - accuracy: 0.7958\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4430 - accuracy: 0.8058\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8126\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4667 - accuracy: 0.7929\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8096\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4628 - accuracy: 0.7977\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4374 - accuracy: 0.8134\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4434 - accuracy: 0.8121\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4484 - accuracy: 0.8034\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4434 - accuracy: 0.8104\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4417 - accuracy: 0.8069\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4330 - accuracy: 0.8131\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8118\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4352 - accuracy: 0.8134\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4306 - accuracy: 0.8207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4278 - accuracy: 0.8172\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4377 - accuracy: 0.8083\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.8215\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4344 - accuracy: 0.8148\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.8012\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.8115\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8261\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4182 - accuracy: 0.8207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8156\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4092 - accuracy: 0.8337\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4263 - accuracy: 0.8169\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4482 - accuracy: 0.8050\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.8226\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8191\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8188\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4148 - accuracy: 0.8253\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4211 - accuracy: 0.8267\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8218\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4245 - accuracy: 0.8177\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8218\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.8299\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4539 - accuracy: 0.7996\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4284 - accuracy: 0.8207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.8202\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4121 - accuracy: 0.8264\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4102 - accuracy: 0.8296\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4054 - accuracy: 0.8326\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8280\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3948 - accuracy: 0.8369\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4023 - accuracy: 0.8353\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4100 - accuracy: 0.8280\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8359\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4105 - accuracy: 0.8294\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3880 - accuracy: 0.8380\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4076 - accuracy: 0.8304\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4163 - accuracy: 0.8231\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3833 - accuracy: 0.8448\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3948 - accuracy: 0.8434\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3984 - accuracy: 0.8359\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3913 - accuracy: 0.8367\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3937 - accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4268 - accuracy: 0.8196\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.3876 - accuracy: 0.8418\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4028 - accuracy: 0.8350\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3930 - accuracy: 0.8410\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3827 - accuracy: 0.8461\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.8313\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4062 - accuracy: 0.8348\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4234 - accuracy: 0.8177\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3850 - accuracy: 0.8402\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3836 - accuracy: 0.8464\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3926 - accuracy: 0.8440\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3872 - accuracy: 0.8396\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3733 - accuracy: 0.8486\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8483\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4023 - accuracy: 0.8348\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3763 - accuracy: 0.8467\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3732 - accuracy: 0.8510\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4261 - accuracy: 0.8207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3902 - accuracy: 0.8405\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8496\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3717 - accuracy: 0.8529\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3857 - accuracy: 0.8423\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3600 - accuracy: 0.8602\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3761 - accuracy: 0.8510\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3673 - accuracy: 0.8532\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3851 - accuracy: 0.8437\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3693 - accuracy: 0.8510\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3654 - accuracy: 0.8556\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3581 - accuracy: 0.8615\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3944 - accuracy: 0.8353\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3540 - accuracy: 0.8599\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3881 - accuracy: 0.8383\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8448\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3664 - accuracy: 0.8583\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3618 - accuracy: 0.8559\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3718 - accuracy: 0.8513\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3823 - accuracy: 0.8442\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3589 - accuracy: 0.8526\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3675 - accuracy: 0.8515\n",
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = buildclassifier, epochs = 200)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train_r, y = y_train, cv = 6)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.7189570152019407\n",
      "Accuracy variance: 0.027899708347895104\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiying decision tree and fitting it\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc_y = dtc.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6855855855855856\n",
      "Precision Score : 0.7064220183486238\n",
      "Recall Score : 0.6707317073170732\n",
      "F1 Score : 0.6881143878462913\n"
     ]
    }
   ],
   "source": [
    "dtc_pred = dtc_y.predict(x_test_r)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,dtc_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,dtc_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,dtc_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,dtc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[376 160]\n",
      " [189 385]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,dtc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying random forest tree and fitting it\n",
    "rfc= RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "rfc_y = rfc.fit(x_train_r,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7747747747747747\n",
      "Precision Score : 0.7852112676056338\n",
      "Recall Score : 0.7770034843205574\n",
      "F1 Score : 0.7810858143607706\n"
     ]
    }
   ],
   "source": [
    "rfc_pred = rfc_y.predict(x_test_r)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,rfc_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,rfc_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,rfc_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,rfc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[414 122]\n",
      " [128 446]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,rfc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC classiying and fitting\n",
    "svc = SVC(random_state=42)\n",
    "svc_y = svc.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7864864864864864\n",
      "Precision Score : 0.8025134649910234\n",
      "Recall Score : 0.7787456445993032\n",
      "F1 Score : 0.790450928381963\n"
     ]
    }
   ],
   "source": [
    "svc_pred = svc_y.predict(x_test_r)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,svc_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,svc_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,svc_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,svc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[426 110]\n",
      " [127 447]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,svc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression classifying and fittnig\n",
    "lr = LogisticRegression()\n",
    "lr_y = lr.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7018018018018019\n",
      "Precision Score : 0.7237569060773481\n",
      "Recall Score : 0.6846689895470384\n",
      "F1 Score : 0.7036705461056401\n"
     ]
    }
   ],
   "source": [
    "lr_pred = lr_y.predict(x_test_r)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,lr_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,lr_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,lr_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[386 150]\n",
      " [181 393]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn classifying and fittnig\n",
    "knn = KNeighborsClassifier()\n",
    "knn_y = knn.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors accuracy 0.7117117117117117\n"
     ]
    }
   ],
   "source": [
    "#knn accuracy\n",
    "kscore = knn.score(x_test_r,y_test)\n",
    "print(\"KNeighbors accuracy\", kscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7117117117117117\n",
      "Precision Score : 0.7702127659574468\n",
      "Recall Score : 0.6306620209059234\n",
      "F1 Score : 0.6934865900383141\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_y.predict(x_test_r)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,knn_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,knn_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,knn_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,knn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[386 150]\n",
      " [181 393]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7189570152019407, 0.6891891891891891, 0.7738738738738739, 0.7801801801801802, 0.69009009009009, 0.7117117117117117]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results.append(mean)\n",
    "results.append(dscore)\n",
    "results.append(rscore)\n",
    "results.append(sscore)\n",
    "results.append(lscore)\n",
    "results.append(kscore)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('classifier', KerasClassifier(\n",
      "\tmodel=None\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=rmsprop\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=None\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=1\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=1\n",
      "\tclass_weight=None\n",
      ")), ('dtc', DecisionTreeClassifier()), ('rfc', RandomForestClassifier()), ('svc', SVC()), ('ls', LogisticRegression()), ('knn', KNeighborsClassifier())]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('classifier', KerasClassifier()))\n",
    "models.append(('dtc', DecisionTreeClassifier()))\n",
    "models.append(('rfc', RandomForestClassifier()))\n",
    "models.append(('svc', SVC()))\n",
    "models.append(('ls', LogisticRegression()))\n",
    "models.append(('knn', KNeighborsClassifier()))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is something I was working on; the gridsearch. But, couldn't get it to work for this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "rfc= RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe = Pipeline(steps = [('scaler', minmax), ('classifier', dtr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe.fit(x_train_r, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = [{'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15]}, \n",
    "              {'classifier':[dtc], \n",
    "               'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_leaf_nodes': [None,10,20,50,100]}, \n",
    "              {'classifier':[rfc], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "              {'classifier':[svc], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "               {'classifier':[lr], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "               {'classifier':[knn], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "              {'classifier':[dtr], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]},\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, cv = 5, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_model = grid_search.fit(x_train_r, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
