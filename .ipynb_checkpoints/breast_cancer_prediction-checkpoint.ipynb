{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading images and their labels\n",
    "X = np.load('X.npy') # images\n",
    "Y = np.load('Y.npy') # labels for the images (0 = no IDC, 1 = IDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[226 164 206]\n",
      "   [224 154 196]\n",
      "   [225 175 211]\n",
      "   ...\n",
      "   [240 221 237]\n",
      "   [232 184 214]\n",
      "   [243 213 235]]\n",
      "\n",
      "  [[217 142 188]\n",
      "   [221 130 179]\n",
      "   [224 150 196]\n",
      "   ...\n",
      "   [227 170 204]\n",
      "   [229 180 215]\n",
      "   [236 212 232]]\n",
      "\n",
      "  [[237 178 212]\n",
      "   [229 157 199]\n",
      "   [218 125 175]\n",
      "   ...\n",
      "   [221 184 217]\n",
      "   [190 153 193]\n",
      "   [227 164 208]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[217 145 192]\n",
      "   [214 129 184]\n",
      "   [212 129 183]\n",
      "   ...\n",
      "   [194 122 185]\n",
      "   [204 143 193]\n",
      "   [189 129 188]]\n",
      "\n",
      "  [[218 144 192]\n",
      "   [213 128 185]\n",
      "   [208 121 171]\n",
      "   ...\n",
      "   [136  79 145]\n",
      "   [184 111 174]\n",
      "   [188 112 176]]\n",
      "\n",
      "  [[212 125 181]\n",
      "   [211 136 181]\n",
      "   [220 162 206]\n",
      "   ...\n",
      "   [127  90 152]\n",
      "   [213 167 202]\n",
      "   [215 180 211]]]\n",
      "\n",
      "\n",
      " [[[219 150 197]\n",
      "   [217 158 201]\n",
      "   [228 173 205]\n",
      "   ...\n",
      "   [198 165 199]\n",
      "   [230 204 224]\n",
      "   [231 193 221]]\n",
      "\n",
      "  [[223 150 195]\n",
      "   [222 140 192]\n",
      "   [213 133 186]\n",
      "   ...\n",
      "   [218 143 193]\n",
      "   [218 148 197]\n",
      "   [215 131 185]]\n",
      "\n",
      "  [[203 125 176]\n",
      "   [218 143 192]\n",
      "   [227 163 199]\n",
      "   ...\n",
      "   [210 137 188]\n",
      "   [203 121 177]\n",
      "   [192 124 183]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[247 234 242]\n",
      "   [247 249 248]\n",
      "   [248 247 247]\n",
      "   ...\n",
      "   [245 240 242]\n",
      "   [249 244 247]\n",
      "   [243 234 239]]\n",
      "\n",
      "  [[249 243 246]\n",
      "   [243 240 247]\n",
      "   [248 241 246]\n",
      "   ...\n",
      "   [247 247 251]\n",
      "   [247 244 246]\n",
      "   [249 246 251]]\n",
      "\n",
      "  [[230 204 226]\n",
      "   [246 247 244]\n",
      "   [250 245 249]\n",
      "   ...\n",
      "   [249 243 250]\n",
      "   [251 248 248]\n",
      "   [248 247 247]]]\n",
      "\n",
      "\n",
      " [[[248 245 249]\n",
      "   [248 246 248]\n",
      "   [249 246 253]\n",
      "   ...\n",
      "   [249 249 248]\n",
      "   [247 246 249]\n",
      "   [248 244 248]]\n",
      "\n",
      "  [[248 246 246]\n",
      "   [248 245 247]\n",
      "   [250 248 248]\n",
      "   ...\n",
      "   [249 243 246]\n",
      "   [252 244 247]\n",
      "   [249 250 247]]\n",
      "\n",
      "  [[241 231 238]\n",
      "   [239 225 240]\n",
      "   [243 237 242]\n",
      "   ...\n",
      "   [248 244 251]\n",
      "   [245 248 249]\n",
      "   [249 242 251]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[248 247 249]\n",
      "   [248 247 249]\n",
      "   [248 247 249]\n",
      "   ...\n",
      "   [245 242 245]\n",
      "   [241 227 238]\n",
      "   [216 159 203]]\n",
      "\n",
      "  [[248 247 249]\n",
      "   [248 247 249]\n",
      "   [249 247 249]\n",
      "   ...\n",
      "   [249 242 249]\n",
      "   [229 193 222]\n",
      "   [161 111 171]]\n",
      "\n",
      "  [[249 247 249]\n",
      "   [249 247 249]\n",
      "   [249 247 249]\n",
      "   ...\n",
      "   [247 248 247]\n",
      "   [235 210 230]\n",
      "   [186 120 177]]]]\n"
     ]
    }
   ],
   "source": [
    "#making sure the data for X crossed over correctly\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#making sure the data for Y crosssed over correctly\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5547\n"
     ]
    }
   ],
   "source": [
    "#total number of images \n",
    "print('Total number of images: {}'.format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative IDC Images: 2759\n"
     ]
    }
   ],
   "source": [
    "#total number of negative IDC images\n",
    "print('Number of negative IDC Images: {}'.format(np.sum(Y==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive IDC Images: 2788\n"
     ]
    }
   ],
   "source": [
    "#total number of positive IDC images\n",
    "print('Number of positive IDC Images: {}'.format(np.sum(Y==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (Width, Height, Channels): (50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "#shape of the images\n",
    "print('Image shape (Width, Height, Channels): {}'.format(X[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Sample Size\n",
    "x_train = x_train[0:30000] \n",
    "y_train = y_train[0:30000]\n",
    "x_test = x_test[0:30000] \n",
    "y_test = y_test[0:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale pizel intensity\n",
    "x_train = x_train / 256.0\n",
    "x_test = x_test / 256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (4437, 50, 50, 3)\n",
      "Testing Data Shape: (1110, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "#verifying shape\n",
    "print(\"Training Data Shape:\", x_train.shape)\n",
    "print(\"Testing Data Shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the first five images in the training set along with the labels\n",
    "for i in range(5):\n",
    "    plt.imshow(x_train[i], cmap='gray'), plt.axis(\"off\")\n",
    "    plt.title('IDC = %d'%y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.9453125  0.95703125 0.94921875]\n",
      "   [0.94921875 0.94140625 0.9453125 ]\n",
      "   [0.953125   0.953125   0.95703125]\n",
      "   ...\n",
      "   [0.94921875 0.91796875 0.91796875]\n",
      "   [0.94921875 0.9609375  0.9609375 ]\n",
      "   [0.9453125  0.89453125 0.91796875]]\n",
      "\n",
      "  [[0.953125   0.94140625 0.95703125]\n",
      "   [0.96875    0.9609375  0.96875   ]\n",
      "   [0.9453125  0.92578125 0.94140625]\n",
      "   ...\n",
      "   [0.94921875 0.94140625 0.953125  ]\n",
      "   [0.95703125 0.9296875  0.953125  ]\n",
      "   [0.91015625 0.8359375  0.890625  ]]\n",
      "\n",
      "  [[0.88671875 0.7890625  0.83984375]\n",
      "   [0.9296875  0.92578125 0.94140625]\n",
      "   [0.9296875  0.8828125  0.90625   ]\n",
      "   ...\n",
      "   [0.94140625 0.90625    0.9375    ]\n",
      "   [0.93359375 0.90234375 0.90625   ]\n",
      "   [0.78125    0.57421875 0.70703125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9609375  0.953125   0.96484375]\n",
      "   [0.9453125  0.9296875  0.93359375]\n",
      "   [0.92578125 0.890625   0.91796875]\n",
      "   ...\n",
      "   [0.9296875  0.89453125 0.91015625]\n",
      "   [0.95703125 0.95703125 0.96875   ]\n",
      "   [0.9609375  0.953125   0.94140625]]\n",
      "\n",
      "  [[0.84765625 0.7265625  0.80859375]\n",
      "   [0.9140625  0.85546875 0.890625  ]\n",
      "   [0.94921875 0.9375     0.94140625]\n",
      "   ...\n",
      "   [0.953125   0.953125   0.97265625]\n",
      "   [0.96875    0.95703125 0.95703125]\n",
      "   [0.953125   0.953125   0.95703125]]\n",
      "\n",
      "  [[0.8984375  0.79296875 0.85546875]\n",
      "   [0.90234375 0.76953125 0.828125  ]\n",
      "   [0.9296875  0.89453125 0.9140625 ]\n",
      "   ...\n",
      "   [0.96484375 0.9609375  0.953125  ]\n",
      "   [0.95703125 0.95703125 0.9609375 ]\n",
      "   [0.94921875 0.95703125 0.9609375 ]]]\n",
      "\n",
      "\n",
      " [[[0.85546875 0.62890625 0.73828125]\n",
      "   [0.8125     0.55078125 0.67578125]\n",
      "   [0.828125   0.43359375 0.57421875]\n",
      "   ...\n",
      "   [0.85546875 0.5859375  0.6953125 ]\n",
      "   [0.84375    0.57421875 0.6953125 ]\n",
      "   [0.81640625 0.50390625 0.62890625]]\n",
      "\n",
      "  [[0.8671875  0.60546875 0.71484375]\n",
      "   [0.83984375 0.5703125  0.703125  ]\n",
      "   [0.828125   0.43359375 0.578125  ]\n",
      "   ...\n",
      "   [0.84765625 0.45703125 0.59765625]\n",
      "   [0.828125   0.45703125 0.59375   ]\n",
      "   [0.84765625 0.6640625  0.74609375]]\n",
      "\n",
      "  [[0.91015625 0.6875     0.7734375 ]\n",
      "   [0.85546875 0.57421875 0.6953125 ]\n",
      "   [0.85546875 0.46875    0.6171875 ]\n",
      "   ...\n",
      "   [0.859375   0.4921875  0.6171875 ]\n",
      "   [0.84375    0.4765625  0.609375  ]\n",
      "   [0.859375   0.58203125 0.6875    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7890625  0.4140625  0.57421875]\n",
      "   [0.859375   0.42578125 0.55859375]\n",
      "   [0.859375   0.4921875  0.62109375]\n",
      "   ...\n",
      "   [0.80078125 0.5078125  0.63671875]\n",
      "   [0.75       0.43359375 0.58203125]\n",
      "   [0.8359375  0.6015625  0.71484375]]\n",
      "\n",
      "  [[0.77734375 0.5703125  0.68359375]\n",
      "   [0.828125   0.4453125  0.58984375]\n",
      "   [0.875      0.48828125 0.60546875]\n",
      "   ...\n",
      "   [0.70703125 0.421875   0.5859375 ]\n",
      "   [0.77734375 0.515625   0.65625   ]\n",
      "   [0.83203125 0.52734375 0.640625  ]]\n",
      "\n",
      "  [[0.64453125 0.37890625 0.53515625]\n",
      "   [0.74609375 0.51953125 0.66796875]\n",
      "   [0.85546875 0.4921875  0.6171875 ]\n",
      "   ...\n",
      "   [0.81640625 0.50390625 0.63671875]\n",
      "   [0.83203125 0.4609375  0.60546875]\n",
      "   [0.8203125  0.484375   0.6171875 ]]]\n",
      "\n",
      "\n",
      " [[[0.6484375  0.4296875  0.625     ]\n",
      "   [0.69921875 0.4453125  0.6328125 ]\n",
      "   [0.8046875  0.609375   0.75390625]\n",
      "   ...\n",
      "   [0.84765625 0.3984375  0.58203125]\n",
      "   [0.82421875 0.35546875 0.515625  ]\n",
      "   [0.8046875  0.3203125  0.5       ]]\n",
      "\n",
      "  [[0.5234375  0.37890625 0.58203125]\n",
      "   [0.6796875  0.4765625  0.66015625]\n",
      "   [0.62890625 0.44140625 0.62109375]\n",
      "   ...\n",
      "   [0.84765625 0.38671875 0.53515625]\n",
      "   [0.86328125 0.47265625 0.6640625 ]\n",
      "   [0.8984375  0.58203125 0.71875   ]]\n",
      "\n",
      "  [[0.546875   0.375      0.578125  ]\n",
      "   [0.8046875  0.59765625 0.75      ]\n",
      "   [0.7265625  0.44921875 0.625     ]\n",
      "   ...\n",
      "   [0.79296875 0.33203125 0.515625  ]\n",
      "   [0.83984375 0.40625    0.578125  ]\n",
      "   [0.87890625 0.53125    0.69140625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.45703125 0.296875   0.51953125]\n",
      "   [0.58203125 0.375      0.56640625]\n",
      "   [0.79296875 0.51953125 0.671875  ]\n",
      "   ...\n",
      "   [0.83984375 0.35546875 0.53515625]\n",
      "   [0.85546875 0.515625   0.66796875]\n",
      "   [0.81640625 0.578125   0.72265625]]\n",
      "\n",
      "  [[0.7109375  0.50390625 0.6640625 ]\n",
      "   [0.73046875 0.53125    0.69140625]\n",
      "   [0.55078125 0.3515625  0.59375   ]\n",
      "   ...\n",
      "   [0.7734375  0.33203125 0.51953125]\n",
      "   [0.82421875 0.34765625 0.55078125]\n",
      "   [0.8671875  0.50390625 0.6484375 ]]\n",
      "\n",
      "  [[0.60546875 0.359375   0.5703125 ]\n",
      "   [0.390625   0.22265625 0.453125  ]\n",
      "   [0.63671875 0.44921875 0.625     ]\n",
      "   ...\n",
      "   [0.78125    0.5234375  0.671875  ]\n",
      "   [0.77734375 0.3046875  0.50390625]\n",
      "   [0.83203125 0.390625   0.58203125]]]]\n"
     ]
    }
   ],
   "source": [
    "#printing the data to show that it's now 0-1\n",
    "print(x_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (4437, 7500)\n",
      "x_test shape:  (1110, 7500)\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "x_train_r = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3])\n",
    "x_test_r = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3])\n",
    "\n",
    "print(\"x_train shape: \",x_train_r.shape)\n",
    "print(\"x_test shape: \",x_test_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildclassifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_r.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5123\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5134\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5494\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6008\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6557\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.6110 - accuracy: 0.6822\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7016\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.5872 - accuracy: 0.7033\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7098\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.5754 - accuracy: 0.7160\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7290\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.5508 - accuracy: 0.7392\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7398\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7355\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7441\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7530\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7557\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7566\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7468\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7598\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7606\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7687\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7549\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7539\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7676\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7598\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7676\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7631\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7679\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7733\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7614\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7706\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7709\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7647\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7658\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7706\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7671\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7741\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7704\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7549\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7668\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7733\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7658\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7722\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7717\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7736\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7823\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7744\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7763\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7720\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7766\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7785\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7690\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7823\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7798\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7831\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7728\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7763\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7663\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7863\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7858\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7828\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7871\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7809\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7806\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7871\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7871\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7855\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7852\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7874\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7879\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7812\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7890\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7844\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7896\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7860\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7823\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7917\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7833\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7917\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7947\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7890\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7952\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7950\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7885\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7925\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7855\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7931\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7882\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7931\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7966\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7871\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7917\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7925\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7906\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7917\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7971\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7839\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8036\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7996\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8025\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7912\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8004\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8001\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7944\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7998\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8050\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8088\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7974\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7952\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8066\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7958\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8036\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7971\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8066\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8036\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8098\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8058\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8028\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8009\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8096\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8012\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8069\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7966\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8085\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8015\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8061\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8112\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8134\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8112\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8196\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8180\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8136\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8063\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8020\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8047\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.8185\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8147\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8063\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8190\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8144\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8215\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8147\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8193\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8088\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8150\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8220\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8109\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8234\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8163\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8158\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8217\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8196\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8231\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8242\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8220\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8261\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8277\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8231\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8331\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8109\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8318\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8144\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8299\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8220\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8334\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8236\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8261\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8185\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8336\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8209\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8212\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8372\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8288\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8304\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8217\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8364\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8369\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8296\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8355\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8345\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8410\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8323\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8234\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8434\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8336\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8410\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8493\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8453\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8410\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8434\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8404\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8410\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8404\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8447\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8212\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8447\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8382\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8499\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8493\n",
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.4936\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5483\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6116\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6873\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6895\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7019\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7190\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7249\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7438\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7395\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7493\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7441\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7601\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7582\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7582\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7579\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7517\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7633\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7652\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7685\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7739\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7587\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7633\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7709\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7639\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7658\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7663\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7693\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7763\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7631\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7598\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7709\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7820\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7763\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7774\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7758\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7687\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7852\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7777\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7817\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7763\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7663\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7836\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7655\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7866\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7828\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7560\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7882\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7801\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7793\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7858\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7814\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7863\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7839\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7758\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7758\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7814\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7839\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7877\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7825\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7866\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7898\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7847\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7925\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7858\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7890\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7801\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7939\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7993\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7966\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7777\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7912\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8006\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7860\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7963\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7985\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7928\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7909\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7990\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7979\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8047\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8036\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7961\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7988\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7944\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8025\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7890\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7871\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8112\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8006\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7963\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8080\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8015\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7979\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8090\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8066\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7979\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8080\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7963\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8096\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8006\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8158\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8117\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8174\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8104\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8150\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8120\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8136\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8139\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8126\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8150\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8180\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8144\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7955\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8215\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8247\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8169\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8223\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8088\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8169\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8288\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8163\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8042\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8190\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8242\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8291\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8169\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8315\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8274\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8074\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8280\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8096\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8139\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8190\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8274\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8245\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8209\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8261\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8282\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8131\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8320\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8361\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8358\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8282\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8369\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8169\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8361\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8209\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8358\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8301\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8085\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8374\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8396\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8247\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8518\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8472\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.8561\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8593\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8372\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8602\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.6971\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7993\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8185\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8193\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8245\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8247\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8234\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8185\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8266\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8282\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8293\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8396\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8263\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8201\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8304\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8388\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8247\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8174\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8299\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8380\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8361\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8437\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8347\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8182\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8334\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8415\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8391\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8261\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8204\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8277\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8469\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8466\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8450\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8293\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.3945 - accuracy: 0.8472\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8410\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8496\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5177\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5834\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6473\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6841\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6938\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7011\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6884\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7173\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7341\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7444\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7506\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7487\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7198\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7585\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7609\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.7585\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7625\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7736\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7598\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7612\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7582\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7549\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7771\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7701\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7671\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7714\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7668\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7747\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7750\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7731\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7796\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7658\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7717\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7809\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7790\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7752\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7801\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7760\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7768\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7682\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7777\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7852\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7860\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7763\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7828\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7785\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7877\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7909\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7850\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7820\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7887\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7806\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7858\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7755\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7852\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7869\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7885\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7869\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7906\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7961\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7866\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7961\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7912\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7974\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7839\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7944\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7828\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7985\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7939\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7896\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8061\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8042\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7906\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7947\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7971\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7979\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7974\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8017\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8004\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8001\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7947\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8080\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8080\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7993\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.4668 - accuracy: 0.7923\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8058\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8004\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7982\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7963\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.7944\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7996\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8131\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4494 - accuracy: 0.8101\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8066\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.8085\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.4375 - accuracy: 0.8158\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8115\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8139\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8150\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8128\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8096\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7963\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8163\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8023\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8163\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8052\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8088\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8239\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.8063\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7852\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8001\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8201\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8209\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8272\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8090\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8134\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8158\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8171\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8212\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8220\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8093\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8182\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8309\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8158\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8153\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8266\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8220\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8247\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.4218 - accuracy: 0.8207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8250\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8282\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8242\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8320\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8231\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8345\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8253\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8190\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8301\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8318\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8185\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8318\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8439\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8415\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8180\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8374\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8285\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8326\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8134\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8364\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8296\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8410\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8255\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8309\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8442\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8180\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8423\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8361\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8439\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8401\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8418\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8223\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8388\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8410\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8450\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8309\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8326\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8336\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8223\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8326\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8277\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8550\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8518\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8334\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8372\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8404\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8547\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8531\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8534\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8520\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8512\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8420\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8542\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8529\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8534\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8585\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8445\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8634\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8602\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8553\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8504\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8537\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8320\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8507\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8596\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8593\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8558\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8650\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8577\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8515\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8648\n",
      "24/24 [==============================] - 0s 971us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5016\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5644\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6449\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.6779\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6963\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7109\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7185\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7304\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7412\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7342\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7531\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7512\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7518\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7618\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7628\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7539\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7664\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7566\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7577\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7626\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7715\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7612\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7669\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7704\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7585\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7693\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7550\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7601\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7661\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7650\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7699\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7723\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7756\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7626\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7756\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7761\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7845\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7653\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7747\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7785\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7718\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7829\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7810\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7820\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4894 - accuracy: 0.7734\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7788\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7823\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7834\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7856\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7756\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7842\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7883\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7869\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7915\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7815\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7791\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7796\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7891\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7918\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7926\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7807\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7888\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7931\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7964\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7942\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7918\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7942\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7920\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7926\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7839\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7888\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8031\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7904\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7853\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7904\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7926\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7904\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7977\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8061\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7888\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8088\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8010\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7934\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7845\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8007\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8039\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7950\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8088\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7996\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8007\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.8034\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8056\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7977\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8050\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.8039\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8110\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8104\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8026\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.8150\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8091\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8104\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7823\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.8053\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8099\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8102\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7983\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8039\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8091\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8110\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.8164\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8091\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8156\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8118\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8131\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8167\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8094\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8080\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8229\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8126\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.8202\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8191\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8099\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8164\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8256\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8199\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8248\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8191\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8213\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8150\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8215\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8194\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8237\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8326\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8202\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.8023\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8304\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.8294\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8318\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8240\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8329\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8345\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8267\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8256\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8234\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8375\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8221\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8304\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8340\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8321\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8299\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8391\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8340\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8345\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8353\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8318\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8367\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8280\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8388\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8183\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8375\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8429\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8472\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8478\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8394\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8413\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8340\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8386\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8469\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8469\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8467\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8564\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8426\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8480\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8518\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8510\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8426\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8594\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8461\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8537\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8524\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8551\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8513\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8483\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8437\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8561\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8553\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8496\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8645\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8597\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8529\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8459\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8661\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8670\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8456\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3517 - accuracy: 0.8588\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8486\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8580\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8661\n",
      "24/24 [==============================] - 0s 953us/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5041\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5062\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5062\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5062\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5062\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5062\n",
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brean\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5187\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5254\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6149\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6604\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.6817\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7082\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7234\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7342\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7409\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7271\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7572\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7361\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7607\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.5195 - accuracy: 0.7501\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.5082 - accuracy: 0.7591\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7620\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7610\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7572\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7572\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7707\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7658\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7610\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7637\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7737\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - 1s 4ms/step - loss: 0.4872 - accuracy: 0.7712\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7574\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7758\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7685\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7718\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7823\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7712\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7593\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7780\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7758\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7761\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7766\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7788\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7766\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7685\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7707\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7726\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7837\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7858\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7796\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7793\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7869\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7788\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7807\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7888\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7793\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7856\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7804\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7853\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7864\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7896\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7856\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7796\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7891\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7807\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7777\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7912\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7920\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7915\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7929\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7929\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7904\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7966\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7991\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7996\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7958\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8018\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7945\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7994\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7920\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7869\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8018\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7910\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7961\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7994\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.8069\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7988\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8042\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7837\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8034\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8096\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8048\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8056\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7861\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8061\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8002\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7818\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.8069\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8045\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7875\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8010\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8039\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8104\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8015\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8077\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8180\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7980\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7920\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8123\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8102\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8158\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8048\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8140\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8104\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8104\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8210\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8283\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8140\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8134\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8240\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8269\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8283\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8294\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8334\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8221\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8253\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8294\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8386\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.8056\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8156\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8367\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8337\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8510\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8350\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8296\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8304\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8391\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8423\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8407\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8378\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8453\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8410\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8348\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8518\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8572\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8548\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8569\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8602\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8451\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8494\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8605\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8386\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8499\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8572\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8448\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8513\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8545\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8667\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8583\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8651\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8605\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8691\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8672\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8605\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8691\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8634\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8480\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8453\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8653\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8640\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8521\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8691\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8688\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8780\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8661\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8621\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8632\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8745\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8767\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8737\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8578\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8643\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8602\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8670\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8488\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8791\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8870\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8889\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8118\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8748\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8767\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8859\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8129\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8764\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2819 - accuracy: 0.8797\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.8918\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8724\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8905\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8505\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8802\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8848\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8721\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8807\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8867\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8978\n",
      "24/24 [==============================] - 0s 995us/step\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = buildclassifier, epochs = 200)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train_r, y = y_train, cv = 6)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean: 0.6837581830815932\n",
      "Accuracy variance: 0.08335772860678341\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifiying decision tree and fitting it\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score:  0.6756756756756757\n"
     ]
    }
   ],
   "source": [
    "#running the accuracy of the decision tree\n",
    "dscore = dtc.score(x_test_r,y_test)\n",
    "print(\"Decision Tree Score: \", dscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifying random forest tree and fitting it\n",
    "rfc= RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "rfc.fit(x_train_r,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score:  0.7657657657657657\n"
     ]
    }
   ],
   "source": [
    "#accuracy of random forest\n",
    "rscore=rfc.score(x_test_r,y_test)\n",
    "print(\"Random Forest Score: \", rscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC classiying and fitting\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of SVC\n",
    "sscore = svc.score(x_test_r,y_test)\n",
    "print (\"SVM Accuracy:\", sscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression classifying and fittnig\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logisitic regression accuracy\n",
    "lscore = lr.score(x_test_r,y_test)\n",
    "print(\"logistic Regression accuracy\", lscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression classifying and fittnig\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_r,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logisitic regression accuracy\n",
    "kscore = knn.score(x_test_r,y_test)\n",
    "print(\"KNeighbors accuracy\", kscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append(mean)\n",
    "results.append(dscore)\n",
    "results.append(rscore)\n",
    "results.append(sscore)\n",
    "results.append(lscore)\n",
    "results.append(kscore)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('classifier', KerasClassifier()))\n",
    "models.append(('dtc', DecisionTreeClassifier()))\n",
    "models.append(('rfc', RandomForestClassifier()))\n",
    "models.append(('svc', SVC()))\n",
    "models.append(('ls', LogisticRegression()))\n",
    "models.append(('knn', KNeighborsClassifier()))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "rfc= RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('scaler', minmax), ('classifier', dtr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('classifier', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train_r, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15]}, \n",
    "              {'classifier':[dtc], \n",
    "               'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_leaf_nodes': [None,10,20,50,100]}, \n",
    "              {'classifier':[rfc], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "              {'classifier':[svc], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "               {'classifier':[lr], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "               {'classifier':[knn], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]}, \n",
    "              {'classifier':[dtr], \n",
    "              'classifier__max_depth': [2,6,8,10], \n",
    "              'classifier__min_samples_split': [2,5,10,15], \n",
    "              'classifier__max_features': [2,3,4,5,6]},\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, cv = 5, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = grid_search.fit(x_train_r, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
